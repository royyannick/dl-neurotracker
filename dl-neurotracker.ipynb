{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Constants #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import LSTM\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "OUTPUT_FNAME = 'RESULT.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Split: Train & Test Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR_C1 = './Data/Halo-NoHalo/Halo/'\n",
    "#DATA_DIR_C2 = './Data/Halo-NoHalo/NoHalo/'\n",
    "\n",
    "#IMG_SIZE_W = 610\n",
    "#IMG_SIZE_L = 610\n",
    "\n",
    "DATA_DIR_C1 = './Data/Halo-NoHalo_small/Halo/'\n",
    "DATA_DIR_C2 = './Data/Halo-NoHalo_small/NoHalo/'\n",
    "\n",
    "IMG_SIZE_W = 32\n",
    "IMG_SIZE_L = 32\n",
    "\n",
    "def load_data():\n",
    "    data = []\n",
    "    nbImages = 0\n",
    "    for fname in tqdm(os.listdir(DATA_DIR_C1)):\n",
    "        label = 1\n",
    "        img = Image.open(DATA_DIR_C1 + fname)\n",
    "        data.append([np.array(img), np.array(label)])\n",
    "        nbImages+=1\n",
    "\n",
    "    for fname in tqdm(os.listdir(DATA_DIR_C2)):\n",
    "        label = 0\n",
    "        img = Image.open(DATA_DIR_C2 + fname)\n",
    "        data.append([np.array(img), np.array(label)])\n",
    "        nbImages+=1\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)\n",
    "data_train = data[0:250]\n",
    "data_test = data[250:350]\n",
    "print(len(data_train))\n",
    "print(len(data_test))\n",
    "\n",
    "X_train = np.array([d[0] for d in data_train])\n",
    "Y_train = np.array([d[1] for d in data_train])\n",
    "\n",
    "X_test = np.array([d[0] for d in data_test])\n",
    "Y_test = np.array([d[1] for d in data_test])\n",
    "\n",
    "print('X_train: ' + str(len(X_train)))\n",
    "print('Y_train: ' + str(len(Y_train)))\n",
    "print('X_test: ' + str(len(X_test)))\n",
    "print('Y_test: ' + str(len(Y_test)))\n",
    "\n",
    "data = []\n",
    "data_train = []\n",
    "data_test = []\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, IMG_SIZE_W, IMG_SIZE_L)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, IMG_SIZE_W, IMG_SIZE_L)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Input shape: ' + str(X_train[0].shape))\n",
    "print('Output shape: ' + str(Y_train[0].shape))\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('Y_train shape: ' + str(Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1,IMG_SIZE_W, IMG_SIZE_L), data_format=\"channels_first\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# 9. Fit model on training data\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=16, epochs=10, verbose=1)\n",
    " \n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "\n",
    "\n",
    "DATA_TRAIN_DIR = './Data/Grey/Test_1/'\n",
    "\n",
    "training_fnames = natural_sort(os.listdir(DATA_TRAIN_DIR))\n",
    "training_fnames.remove(OUTPUT_FNAME)\n",
    "\n",
    "output_fname = OUTPUT_FNAME\n",
    "\n",
    "imgs = list()\n",
    "for fname in training_fnames:\n",
    "    imgs.append(Image.open(DATA_TRAIN_DIR + fname))\n",
    "\n",
    "output_img = Image.open(DATA_TRAIN_DIR + output_fname)\n",
    "    \n",
    "print(len(imgs))\n",
    "\n",
    "fig = plt.figure(figsize=(40,30))\n",
    "\n",
    "for i in range(0, len(imgs)):\n",
    "    f = fig.add_subplot(9,9,i+1)\n",
    "    f.imshow(imgs[i],cmap='gray')\n",
    "\n",
    "f = fig.add_subplot(9,9,len(imgs))\n",
    "f.imshow(output_img, cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num, data in enumerate(train_data[24:36]):\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = orig #img_data.reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "    \n",
    "    #model_out = model.predict([data])[0]\n",
    "    \n",
    "    if img_num[0] == 0: str_label = 'Dog'\n",
    "    else: str_label = 'Cat'\n",
    "        \n",
    "    y.imshow(orig)\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying this: https://arxiv.org/pdf/1504.01561.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    " \n",
    "# 4. Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "# 5. Preprocess input data\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    " \n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format=\"channels_first\"))\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# 9. Fit model on training data\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=16, epochs=5, verbose=1)\n",
    " \n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Preprocessing #\n",
    "Opening Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_IN_DIR = './Data/Color/'\n",
    "DATA_OUT_DIR = './Data/Grey/'\n",
    "\n",
    "INPUT_SIZE_W = 1127\n",
    "INPUT_SIZE_L = 634\n",
    "OUTPUT_SIZE_W = 610\n",
    "OUTPUT_SIZE_L = 610\n",
    "\n",
    "ori_files = os.listdir(DATA_IN_DIR)\n",
    "\n",
    "for fname in ori_files:\n",
    "    img = Image.open(DATA_IN_DIR + fname).convert('L')\n",
    "    img = img.crop(((INPUT_SIZE_W/2)-(OUTPUT_SIZE_W/2),(INPUT_SIZE_L/2)-(OUTPUT_SIZE_L/2), (INPUT_SIZE_W/2)+(OUTPUT_SIZE_W/2), (INPUT_SIZE_L/2)+(OUTPUT_SIZE_L/2)))\n",
    "    img.save(DATA_OUT_DIR + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Downsizing #\n",
    "Opening Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_C1 = './Data/Halo-NoHalo/Halo/'\n",
    "DATA_DIR_C2 = './Data/Halo-NoHalo/NoHalo/'\n",
    "DATA_DIR_C1_OUT = './Data/Halo-NoHalo_small/Halo/'\n",
    "DATA_DIR_C2_OUT = './Data/Halo-NoHalo_small/NoHalo/'\n",
    "\n",
    "INPUT_SIZE_W = 610\n",
    "INPUT_SIZE_L = 610\n",
    "OUTPUT_SIZE_W = 32\n",
    "OUTPUT_SIZE_L = 32\n",
    "\n",
    "ori_files = os.listdir(DATA_DIR_C1)\n",
    "for fname in tqdm(ori_files):\n",
    "    img = Image.open(DATA_DIR_C1 + fname)\n",
    "    img_small = cv2.resize(np.array(img), (OUTPUT_SIZE_W, OUTPUT_SIZE_L), cv2.INTER_LINEAR)\n",
    "    img2 = Image.fromarray(img_small)\n",
    "    img2.save(DATA_DIR_C1_OUT + fname)\n",
    "    \n",
    "ori_files = os.listdir(DATA_DIR_C2)\n",
    "for fname in tqdm(ori_files):\n",
    "    img = Image.open(DATA_DIR_C2 + fname)\n",
    "    img_small = cv2.resize(np.array(img), (OUTPUT_SIZE_W, OUTPUT_SIZE_L), cv2.INTER_LINEAR)\n",
    "    img2 = Image.fromarray(img_small)\n",
    "    img2.save(DATA_DIR_C2_OUT + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halo vs NoHalo Image Prep #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_IN_DIR = './Data/Color/'\n",
    "DATA_OUT_DIR_C1 = './Data/Grey/Halo/'\n",
    "DATA_OUT_DIR_C2 = './Data/Grey/NoHalo/'\n",
    "\n",
    "INPUT_SIZE_W = 1127\n",
    "INPUT_SIZE_L = 634\n",
    "OUTPUT_SIZE_W = 610\n",
    "OUTPUT_SIZE_L = 610\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "\n",
    "\n",
    "for i in range(1, 2000):\n",
    "    curName = 'Test1_' + str(i)\n",
    "    \n",
    "    # Image Result.\n",
    "    img = Image.open(DATA_IN_DIR + curName + '/RESULT.png').convert('L')\n",
    "    img = img.crop(((INPUT_SIZE_W/2)-(OUTPUT_SIZE_W/2),(INPUT_SIZE_L/2)-(OUTPUT_SIZE_L/2), (INPUT_SIZE_W/2)+(OUTPUT_SIZE_W/2), (INPUT_SIZE_L/2)+(OUTPUT_SIZE_L/2)))\n",
    "    img.save(DATA_OUT_DIR_C1 + curName + '_R.png')\n",
    "    \n",
    "    ori_files = natural_sort(os.listdir(DATA_IN_DIR + curName))\n",
    "    \n",
    "    # Image Identification.\n",
    "    img = Image.open(DATA_IN_DIR + curName + '/' + ori_files[1]).convert('L')\n",
    "    img = img.crop(((INPUT_SIZE_W/2)-(OUTPUT_SIZE_W/2),(INPUT_SIZE_L/2)-(OUTPUT_SIZE_L/2), (INPUT_SIZE_W/2)+(OUTPUT_SIZE_W/2), (INPUT_SIZE_L/2)+(OUTPUT_SIZE_L/2)))\n",
    "    img.save(DATA_OUT_DIR_C1 + curName + '_' + ori_files[1])\n",
    "    \n",
    "    # Image Tracking.\n",
    "    img = Image.open(DATA_IN_DIR + curName + '/' + ori_files[30]).convert('L')\n",
    "    img = img.crop(((INPUT_SIZE_W/2)-(OUTPUT_SIZE_W/2),(INPUT_SIZE_L/2)-(OUTPUT_SIZE_L/2), (INPUT_SIZE_W/2)+(OUTPUT_SIZE_W/2), (INPUT_SIZE_L/2)+(OUTPUT_SIZE_L/2)))\n",
    "    img.save(DATA_OUT_DIR_C2 + curName + '_' + ori_files[30])\n",
    "    \n",
    "    # Image Tracking.\n",
    "    img = Image.open(DATA_IN_DIR + curName + '/' + ori_files[50]).convert('L')\n",
    "    img = img.crop(((INPUT_SIZE_W/2)-(OUTPUT_SIZE_W/2),(INPUT_SIZE_L/2)-(OUTPUT_SIZE_L/2), (INPUT_SIZE_W/2)+(OUTPUT_SIZE_W/2), (INPUT_SIZE_L/2)+(OUTPUT_SIZE_L/2)))\n",
    "    img.save(DATA_OUT_DIR_C2 + curName + '_' + ori_files[50])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
